 
function [gparams,memberships] =  gaussian_mixture(data,K,init_method,epsilon, niterations,plotflag, RSEED)
% [gparams,memberships] =  gaussian_mixture(data,K,init_method,epsilon, 
%                                                niterations,plotflag, RSEED)
%
% Template for a function to fit  a Gaussian mixture model via EM 
% using K mixture components. The data are contained in the N x d "data" matrix. 
%  
% INPUTS
%  data: N x d real-valued data matrix
%  K: number of clusters (mixture components)
%  initialization_method: 1 for memberships, 2 for parameters, 3 for kmeans 
%  epsilon: convergence threshold used to detect convergence
%  niterations (optional): maximum number of iterations to perform (default 500)
%  plotflag (optional): equals 1 to plot parameters during learning, 
%                       0 for no plotting (default is 0)
%  RSEED (optional): initial seed value for the random number generator
%  
%
% OUTPUTS
%  gparams:  2d structure array containing the learned mixture model parameters: 
%           gparams(k).weight = weight of component k
%           gparams(k).mean = d-dimensional mean vector for kth component 
%           gparams(k).covariance = d x d covariance vector for kth component
%
%  memberships: n x K matrix of probability memberships for "data"
%
%  Note: Interpretation of gparams and memberships:
%    - gparams(k).weight is the probability that a randomly selected row
%         belongs to component (or cluster) i (so it is "cluster size")
%    - memberships(i,k) = p(cluster k | x) which is the probability
%         (computed via Bayes rule) that vector x was generated by cluster
%         k, according to the "generative" probabilistic model. 

% your code goes here....

% initialize....

% perform E-step...

% perform M-step...

% compute log-likelihood and print to screen.....

% check for convergence.....

end

